Starting PoDD Stage 1/5
Check the length of the training dataset 50000
GPU_0_using curriculum 98 with window 60
  0%|          | 0/10 [00:04<?, ?it/s]
Traceback (most recent call last):
  File "/home/FYP/spyridon001/PoDD_Modified/main.py", line 67, in <module>
    main_worker(args)
  File "/home/FYP/spyridon001/PoDD_Modified/src/base.py", line 223, in main_worker
    grad_tmp, losses_avg, distill_steps = train(train_loader1, None, model, criterion,
  File "/home/FYP/spyridon001/PoDD_Modified/src/base.py", line 388, in train
    loss.backward()
  File "/home/FYP/spyridon001/.conda/envs/podd_modified/lib/python3.9/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/FYP/spyridon001/.conda/envs/podd_modified/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.44 GiB (GPU 0; 31.73 GiB total capacity; 22.08 GiB already allocated; 1.00 GiB free; 25.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF